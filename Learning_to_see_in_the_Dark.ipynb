{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projet : Learning to See in the Dark\n",
        "Paul-Vinh LÊ, Sébastien Morel"
      ],
      "metadata": {
        "id": "xh8XZPhslHM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Préparation"
      ],
      "metadata": {
        "id": "SD3xPwv2lUpt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Récupération des différents code "
      ],
      "metadata": {
        "id": "rfRYrhAPlZ4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone notre répertoire de code : "
      ],
      "metadata": {
        "id": "a4vmnH_glhTk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D4OP5HkmRMPm"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    !rm -fr pytorch-Learning-to-See-in-the-Dark\n",
        "    !git clone --quiet https://github.com/Paul-Vinh/pytorch-Learning-to-See-in-the-Dark.git \n",
        "\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone le répertoire lié à l'article HDR+"
      ],
      "metadata": {
        "id": "jqeoHcJOloqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    !rm -fr hdr_plus_pytorch\n",
        "    !git clone --quiet https://github.com/martin-marek/hdr-plus-pytorch.git hdr_plus_pytorch\n",
        "\n",
        "except ImportError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "iRy9sPGt103w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecte notre Drive"
      ],
      "metadata": {
        "id": "6YUQDmQSlwBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cela est utile pour sauvegarder les différents résultats de nos experiences, sauvegarder les checkpoints de nos entrainements, les courbes de loss etc... On peut aussi stocker les données. "
      ],
      "metadata": {
        "id": "NKfuTrsAl4qe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgA2H75KQJtb"
      },
      "outputs": [],
      "source": [
        "# Connect colab with Drive\n",
        "persistent_storage = 'trainings/'\n",
        "try:\n",
        "    # Load the Drive helper and mount\n",
        "    from google.colab import drive\n",
        "    import os\n",
        "\n",
        "    # This will prompt for authorization.\n",
        "    drive.mount( 'Drive')\n",
        "    persistent_storage = 'Drive/My Drive/MVA/Imagerie_numérique'\n",
        "    os.makedirs(persistent_storage, exist_ok=True)\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installe les packages nécessaires au code "
      ],
      "metadata": {
        "id": "E7wXQHECmHQm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wjGzMBASsWx"
      },
      "outputs": [],
      "source": [
        "!pip install rawpy\n",
        "!pip install bm3d\n",
        "!pip install multiprocess\n",
        "!pip install pytorch_ssim\n",
        "!pip install gdown\n",
        "!pip install pytorch_msssim\n",
        "!pip install torchgeometry"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Télécharge le dataset"
      ],
      "metadata": {
        "id": "5ejYNVbVmPse"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPjKniSnOxmi"
      },
      "outputs": [],
      "source": [
        "# Get the zip file\n",
        "!wget https://storage.googleapis.com/isl-datasets/SID/Sony.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vN45o3NLrd-D"
      },
      "outputs": [],
      "source": [
        "# unzip it !\n",
        "!mkdir dataset/\n",
        "!unzip -q Sony.zip -d dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1sRQpTKzD9B-"
      },
      "outputs": [],
      "source": [
        "# Remove the zip file\n",
        "!rm Sony.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFqPuLa9O2S9"
      },
      "source": [
        "# Entrainement "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour entrainer le modèle, il faut définir : \n",
        "\n",
        "*   Le dossier où l'on stocke les courbes d'entrainements et les checkpoints. On peut aussi mettre un modèle pour lequel on souhaite continuer plus longtemps l'entrainement.\n",
        "*  La loss que l'on souhaite utiliser (\"ssim\", \"L1\" ou \"L2\").\n",
        "*  Le nombre d'epochs que va prendre l'entrainement. \n",
        "*  La fréquence de sauvegarde des checkpoints save_freq ainsi que la fréquence de validation val_freq qui permet de construire la courbe d'entrainement si plot_loss est True."
      ],
      "metadata": {
        "id": "acTeJMDGnmwD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35t9DqveO1nY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87a6192-3f98-4350-9ad3-6546184884af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"pytorch-Learning-to-See-in-the-Dark/train_Sony.py\", line 10, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/__init__.py\", line 197, in <module>\n",
            "    from torch._C import *  # noqa: F403\n",
            "RuntimeError: KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "!python pytorch-Learning-to-See-in-the-Dark/train_Sony.py --models_dir \"/content/Drive/MyDrive/MVA/Image_bis/\" --loss \"ssim\" --save_freq 10 --val_freq 1  --plot_loss True --epoch 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-mkQAb7Tg6P"
      },
      "source": [
        "# Test du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test sur le test Set de Sony\n",
        "Pour tester la qualité d'un modèle, on peut directement appliquer le script test_Sony qui permet de le tester sur l'ensemble des images du test Set. "
      ],
      "metadata": {
        "id": "eygm0yd2rCBE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCkqkUwRS-nZ"
      },
      "outputs": [],
      "source": [
        "!python pytorch-Learning-to-See-in-the-Dark/test_Sony.py --dataset_dir \"/content/\" --model_dir \"/content/pytorch-Learning-to-See-in-the-Dark/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application du model sur un fichier particulier"
      ],
      "metadata": {
        "id": "ybak9B3PrHRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut également appliquer notre modèle sur un fichier en particulier. Pour cela, on utilse l'argument *file* qui donne le chemin d'accès vers le fichier particulier. \n",
        "<br>\n",
        "Cela permet alors de générer rapidement une output pour une image voulue. \n",
        "<br> On peut également tester la capacité de généralisation de notre modèle pour des images non présentes dans le data set de Sony. Comme on ne dispose pas de ground truth sur ce genre d'image, on définir un argument *generalization* pour pouvoir éviter les étapes de calcul de métriques, impossible sans groundtruth. "
      ],
      "metadata": {
        "id": "VZITYqyPr6zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python pytorch-Learning-to-See-in-the-Dark/test_Sony.py --file \"/content/dataset/Sony/short/00001_00_0.1s.ARW\" --generalization False --dataset_dir \"/content/\" --model_dir \"/content/pytorch-Learning-to-See-in-the-Dark/\""
      ],
      "metadata": {
        "id": "sOJ4OaEQrF5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov558DIyPOhd"
      },
      "source": [
        "# État de l'Art"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour pouvoir comparer la méthode Learning to See in the Dark aux méthodes plus classiques que sont BM3D et HDR+. \n",
        "<br> On va donc générer les résultats de ces méthodes sur le test set, les sauvergarder si nécessaire et calculer leur écart à la ground truth. "
      ],
      "metadata": {
        "id": "hZu1V9U86hdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import des différentes librairies "
      ],
      "metadata": {
        "id": "MxOr1OrEwm46"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KteJN2zxPOpe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage import exposure\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from hdr_plus_pytorch import align\n",
        "import rawpy\n",
        "import imageio\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "\n",
        "import bm3d\n",
        "import rawpy\n",
        "import cv2\n",
        "import multiprocessing as mp\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some usefull functions"
      ],
      "metadata": {
        "id": "i2KjgnBYGjXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ssim(gt_im, pred_im):\n",
        "    \"\"\" Compute SSIM between ground truth image & predicted image.\n",
        "    \"\"\"\n",
        "    return(ssim(gt_im, pred_im,\n",
        "                  data_range=pred_im.max() - pred_im.min(), multichannel=True))"
      ],
      "metadata": {
        "id": "_t13rTh7k7w0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_raw_images(image_paths):\n",
        "    \"\"\"loads bayer pixels from raw images\"\"\"\n",
        "    images = []\n",
        "    for path in image_paths:\n",
        "        with rawpy.imread(path) as raw:\n",
        "            image = raw.raw_image.copy().astype(np.float32)\n",
        "            images.append(image)\n",
        "\n",
        "    # store the pixels in a tensor with an added \"channel\" dimension\n",
        "    images_s = np.stack(images)\n",
        "    images_s = torch.from_numpy(images_s)[:, None, :, :]\n",
        "\n",
        "    print(f'burst of shape {list(images_s.shape)} loaded')\n",
        "    return images_s\n"
      ],
      "metadata": {
        "id": "XfEbuE_u8ORj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_grountruth(image_index, gt_dir):\n",
        "  \"\"\"\n",
        "  Get the ground truth for the image_index \n",
        "  \"\"\"\n",
        "  gt_files = glob(gt_dir + '%s_00*.ARW'%image_index)\n",
        "  gt_path = gt_files[0]\n",
        "  _, gt_fn = os.path.split(gt_path)\n",
        "  in_exposure =  0.1\n",
        "  gt_exposure =  float(gt_fn[9:-5])\n",
        "  ratio = min(gt_exposure/in_exposure,300)\n",
        "\n",
        "  gt_raw = rawpy.imread(gt_path)\n",
        "  sat = gt_raw.white_level\n",
        "  wb = gt_raw.camera_white_level_per_channel\n",
        "  bl = gt_raw.black_level_per_channel\n",
        "  im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
        "  gt_image = np.expand_dims(np.float32(im/65535.0),axis = 0)\n",
        "  \n",
        "  gt_full = gt_image[0,:,:,:]\n",
        "  return (gt_full*255).astype('uint8'), wb, sat, bl\n"
      ],
      "metadata": {
        "id": "GIHnOQIvF4rH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rgb_values(image_path, bayer_array=None, **kwargs):\n",
        "    \"\"\"using a raw file [and modified bayer pixels], get rgb pixels\"\"\"\n",
        "    # open the raw image\n",
        "    with rawpy.imread(image_path) as raw:\n",
        "        # overwrite the original bayer array\n",
        "        if bayer_array is not None:\n",
        "            raw.raw_image[:] = bayer_array\n",
        "        # get postprocessed rgb pixels\n",
        "        rgb = raw.postprocess(**kwargs)\n",
        "    return rgb"
      ],
      "metadata": {
        "id": "p3tuocqO9itj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_index(in_files):\n",
        "  \"\"\"\n",
        "  Get the indexs of the images in the in_files\n",
        "  Return the list of the indexs sorted, whithout dupplicate\n",
        "  \"\"\"\n",
        "  indexs = [i.split('/')[-1] for i in in_files]\n",
        "  indexs = [i.split('_', 1)[0] for i in indexs]\n",
        "  indexs = list(dict.fromkeys(indexs))\n",
        "  indexs.sort()\n",
        "  return indexs"
      ],
      "metadata": {
        "id": "xasl2CoYFRDz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_methods(indexs, input_dir, gt_dir, device, use_BM3D = False, use_HDR = False, scores = None, result_dir = None):\n",
        "  \n",
        "  N = len(indexs)\n",
        "  for i in range(N):\n",
        "    print('Iteration %d sur %d iterations for image %s'%(i, N, indexs[i]))\n",
        "\n",
        "    ## Get file \n",
        "    # Stack images\n",
        "    in_file = glob(input_dir+indexs[i]+'_*_0.1s.ARW')\n",
        "    images = load_raw_images(in_file)\n",
        "    # One image for BM3D\n",
        "    if use_BM3D:\n",
        "      bm_raw = rawpy.imread(in_file[0])\n",
        "\n",
        "    # Get Ground Truth and some parameters\n",
        "    ref_rgb, wb, sat, bl = get_grountruth(indexs[i], gt_dir)\n",
        "    \n",
        "    ## Compute scale of gt\n",
        "    ref_rgb = ref_rgb.astype('float32')\n",
        "    means_gt = np.mean(ref_rgb, axis = (1,0))\n",
        "\n",
        "    if use_HDR:\n",
        "      ## HDR +\n",
        "      print(\"Begin HDR method\")\n",
        "      # Alignement\n",
        "      merged_image = align.align_and_merge(images, device=device)\n",
        "      # Convert raw images to rgb images\n",
        "      merged_rgb = get_rgb_values(in_file[0], merged_image[0],user_wb = wb, user_sat = sat, user_black= bl[0], half_size=False, no_auto_bright=True, output_bps=16)\n",
        "      merged_rgb = merged_rgb.astype('float32')\n",
        "      # Scaling on Gt\n",
        "      #means_rgb = np.mean(merged_rgb, axis = (1,0))\n",
        "      #means =  means_gt/means_rgb\n",
        "      #merged_rgb *= means[None, None, :]\n",
        "      #merged_rgb = exposure.match_histograms(merged_rgb, ref_rgb, multichannel=True)\n",
        "\n",
        "    if use_BM3D:\n",
        "      ## BM3D\n",
        "      print(\"Begin BM3D method\")\n",
        "      # Convert raw images to rgb images\n",
        "      bm3d_rgb = bm_raw.postprocess(user_wb = wb, user_sat = sat, user_black= bl[0], half_size=False, no_auto_bright=True, output_bps=16)\n",
        "      bm3d_rgb = bm3d_rgb.astype('float32')\n",
        "      # Scaling on Gt\n",
        "      means_bm3d = np.mean(bm3d_rgb, axis = (1,0))\n",
        "      bm3d_rgb = (means_gt/means_bm3d) * bm3d_rgb\n",
        "      # Denoising\n",
        "      denoised_rgb = bm3d.bm3d(bm3d_rgb, sigma_psd=0.2, stage_arg=bm3d.BM3DStages.ALL_STAGES)\n",
        "\n",
        "    if scores:\n",
        "      scores['id'].append(indexs[i])\n",
        "      print(\"Compute SSIM\")\n",
        "      ## Compute SSIM comparaison\n",
        "      if use_BM3D:\n",
        "        score_bm3d = compute_ssim(ref_rgb.astype('uint8'), denoised_rgb.astype('uint8'))\n",
        "        print(\"Methode BM3D image {} SSIM = {}\".format(indexs[i], score_bm3d))\n",
        "        scores['BM3D SSIM'].append(score_bm3d)\n",
        "      if use_HDR:\n",
        "        score_hdr = compute_ssim(ref_rgb.astype('uint8'), merged_rgb.astype('uint8'))\n",
        "        print(\"Methode HDR image {} SSIM = {}\".format(indexs[i], score_hdr))\n",
        "        scores['HDR+ SSIM'].append(score_hdr)\n",
        "    \n",
        "    if result_dir:\n",
        "      print(\"Saving file \")\n",
        "      ## Save Images\n",
        "      if use_HDR:\n",
        "        Image.fromarray(merged_rgb.astype('uint8')).save(result_dir + indexs[i] + '_hdr.png')     \n",
        "      if use_BM3D:\n",
        "        Image.fromarray(denoised_rgb.astype('uint8')).save(result_dir + indexs[i] + '_BM3DD.png')                           \n"
      ],
      "metadata": {
        "id": "ZSPwWXqOGyuQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(bm3d.bm3d)"
      ],
      "metadata": {
        "id": "jP0_U1F2izlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the score of each function on test set"
      ],
      "metadata": {
        "id": "alcMyY3CGoIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "P-DuBhMr8ig9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = r\"/content/dataset/Sony/short/\"\n",
        "gt_dir = r\"/content/dataset/Sony/long/\"\n",
        "in_files = glob(input_dir + '1*_*_0.1s.ARW')"
      ],
      "metadata": {
        "id": "Sm9CAN0tFOlN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexs = extract_index(in_files)"
      ],
      "metadata": {
        "id": "tPIi8aSH8RQP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexs = ['10016', '10074', '10106', '10167', '10199', '10187']\n",
        "indexs = ['10016']"
      ],
      "metadata": {
        "id": "SpWB-39dK1nc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_dir = \"/content/Drive/MyDrive/MVA/Imagerie_numérique/State_of_the_art/\""
      ],
      "metadata": {
        "id": "RzrqFDPtKHR8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(indexs)"
      ],
      "metadata": {
        "id": "vlqXRUTXKn1V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {'id': [], 'BM3D SSIM' : [], 'HDR+ SSIM': []}"
      ],
      "metadata": {
        "id": "aLMn4fjyd7i6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_methods(indexs, input_dir, gt_dir, device, use_BM3D = True, use_HDR = True, scores = scores) ### change user_wb = wb wb = camera_white_level_per_channel"
      ],
      "metadata": {
        "id": "EstgquoLnJiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df = pd.DataFrame(scores, columns= ['id', 'BM3D SSIM', 'HDR+ SSIM'])\n",
        "scores_df.set_index(['id'], inplace = True)\n",
        "scores_df.mean()"
      ],
      "metadata": {
        "id": "5ur31d5Suncf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df.to_csv(result_dir + 'Scores_BM3D_HDR.csv')"
      ],
      "metadata": {
        "id": "Ar_C5lcZyOaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Learning_to_see_in_the_Dark.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}